<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Peter Dobranowski" />

<meta name="date" content="2024-08-22" />

<title>Tabular Machine Learning Algorithms</title>

<script src="site_libs/header-attrs-2.28/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="ml_figures.html">Tabular ML Algorithms</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Tabular Machine Learning Algorithms</h1>
<h4 class="author">Peter Dobranowski</h4>
<h4 class="date">2024-08-22</h4>

</div>


<p><img src="ml_figures/Decision_tree.png" width="362" /></p>
<p>Recursively splits observations (classes or values) based on binary
rules. The best rule (split) based on a splitting criterion is placed at
the root of the tree, followed by recursive rules down the branches. The
tree stops being built based on a stopping criteria, such as the number
of observations in a terminal (leaf) node. Predictions are made by
applying the ruleset and applying majority vote (classification) or
averaging values (regression).</p>
<p><img src="ml_figures/Random_forest.png" width="617" /></p>
<p>Constructs a forest (ensemble) of decision trees. Each tree is
constructed using a random subset of samples (with replacement,
i.e. bootstrapping) and features (without replacement). Class votes
(classification) or values (regression) are aggregated across trees and
a final prediction is made. With bootstrap aggregation (“bagging”),
samples not included in one tree can be used to test other trees,
enabling an internal error rate to be calculated that approximates
cross-validation accuracy.</p>
<p><img src="ml_figures/Gradient_boosting.png" width="548" /></p>
<p>Constructs a series of decision trees, beginning with a base decision
tree. Subsequent trees predict the error of the previous tree, which is
multiplied by a weight (i.e. undergoing “shrinkage”), added to the
previous prediction, and all trees are “ensembled” to make the final
predictor. Each iteration seeks to minimize loss using gradient descent.
The sequential addition of improved learners is called “boosting”.</p>
<p><img src="ml_figures/K_nearest_neighbour.png" width="443" /></p>
<p>Transforms observations into a distance matrix, then assigns the
value of the majority class (classification) or average value
(regression) of the observation’s k nearest neighbours.</p>
<p><img src="ml_figures/Linear_regression.png" width="450" /></p>
<p>Fits a straight line to predict an outcome, using a linear
combination of predictor feature coefficients (B). The objective is to
minimize the residuals (squared difference) between X and fitted Y.</p>
<p><img src="ml_figures/PLS_PCR.png" width="678" /></p>
<p>PLS transforms predictors into latent variables (components), that
explain variance in predictors and responses, followed by linear
regression using components as predictors. PCR derives principal
components that explain variance in predictors.</p>
<p><img src="ml_figures/Regularized_regression.png" width="509" /></p>
<p>L1 (lasso) and L2 (ridge) penalties shrink coefficients of low
importance and collinear features towards 0, or to exactly 0, depending
on alpha value.</p>
<p><img src="ml_figures/Neural_network.png" width="332" /></p>
<p>Inspired by biological neural circuitry, the fundamental architecture
of a neural network is a series of layers of neurons (i.e. nodes). Nodes
are the fundamental unit of neural networks, receiving an input or
weighted sum of inputs, applying a linear regression using weights and
biases, and “activating” based on an activation function (e.g. softmax,
sigmoid, rectified linear unit). Nodes are arranged in layers, requiring
an input and output layer, and one or more hidden layers. Neural
networks are trained via forward propagation (inputs flow through the
nodes towards the output layer, which makes a prediction) and back
propagation (adjusting node weights and biases using gradient descent).
The interconnectivity of nodes and nonlinear activation functions enable
leveraging complex patterns underlying the predictive signals in a
dataset. A multi-layer perceptron with one hidden layer is an example of
a simple feedforward neural network.</p>
<p><img src="ml_figures/Support_vector_machine.png" width="412" /></p>
<p>Transforms observations into n-dimensions, and draws a boundary
(classification) or function (regression) (i.e. “hyperplane”).
Observations closest to the hyperplane are called “support vectors”. SVM
seeks to maximize the distance between support vectors of different
classes (the “margin”). A non-linear boundary can be drawn by applying
the “kernel trick”, which transforms the datapoints into a
higher-dimension space.</p>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
